{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Group Members:**\n",
        "\n",
        "Palak Yerawar - 202201040195\n",
        "\n",
        "Surabhi Kharkate - 202201040215\n",
        "\n",
        "Sakshi Lade - 202201040218"
      ],
      "metadata": {
        "id": "Yn7FnOmbvAk7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a-rhdoMq-TZ"
      },
      "source": [
        " ***Headline Generation using Encoder-Decoder Architectures***\n",
        "\n",
        "This notebook implements:\n",
        "- LSTM/GRU-based Encoder-Decoder (No Attention)\n",
        "- Encoder-Decoder with Bahdanau/Luong Attention\n",
        "- Transformer (Self-Attention)\n",
        "\n",
        "dataset link : https://www.kaggle.com/datasets/sahideseker/news-headline-generation-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Implement Encoder-Decoder without Attention (LSTM/GRU)***"
      ],
      "metadata": {
        "id": "w9zFdyaEHds6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import Libraries and Load Dataset"
      ],
      "metadata": {
        "id": "FwnWPvl7-k7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "RBiNC94XQatN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('/content/headlines dataset.csv')\n",
        "# Drop rows with missing values (if any)\n",
        "df.dropna(inplace=True)\n",
        "# Rename columns for convenience\n",
        "df = df[['content_text', 'generated_headline']].rename(columns={'content_text': 'input_text', 'generated_headline': 'target_text'})\n"
      ],
      "metadata": {
        "id": "2eB5aEyw9eu6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Add Special Tokens to Target Text"
      ],
      "metadata": {
        "id": "wFNE9g5G-p67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add <sos> and <eos> tokens to target text\n",
        "df['target_text'] = df['target_text'].apply(lambda x: f'<sos> {x} <eos>')\n"
      ],
      "metadata": {
        "id": "11dpikbn9j0r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Tokenize and Prepare Sequences"
      ],
      "metadata": {
        "id": "-Anv4Y2u-sX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#word → index tokenization\n",
        "# Tokenizer for input text\n",
        "input_tokenizer = Tokenizer()\n",
        "input_tokenizer.fit_on_texts(df['input_text'])  # Build vocab from input text\n",
        "input_vocab_size = len(input_tokenizer.word_index) + 1  # +1 for padding\n",
        "\n",
        "# Tokenizer for target text\n",
        "target_tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n') #keep < and >\n",
        "target_tokenizer.fit_on_texts(df['target_text'])  # Build vocab from target text\n",
        "target_vocab_size = len(target_tokenizer.word_index) + 1  # +1 for padding\n",
        "\n",
        "# Get max sequence lengths\n",
        "max_input_seq_len = max([len(seq.split()) for seq in df['input_text']])\n",
        "max_target_seq_len = max([len(seq.split()) for seq in df['target_text']])\n",
        "\n",
        "# Tokenize and pad input\n",
        "input_sequences = input_tokenizer.texts_to_sequences(df['input_text'])\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_input_seq_len, padding='post')\n",
        "\n",
        "# Tokenize and pad target\n",
        "target_sequences = target_tokenizer.texts_to_sequences(df['target_text'])\n",
        "target_sequences = pad_sequences(target_sequences, maxlen=max_target_seq_len, padding='post')\n",
        "\n",
        "# Split target into decoder input and output\n",
        "target_input_sequences = target_sequences[:, :-1]  # without last token\n",
        "target_output_sequences = target_sequences[:, 1:]  # without first token\n",
        "\n",
        "# Print shapes\n",
        "print(f\"Input Sequences Shape: {input_sequences.shape}\")\n",
        "print(f\"Target Input Sequences Shape: {target_input_sequences.shape}\")\n",
        "print(f\"Target Output Sequences Shape: {target_output_sequences.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzHwcekc9oba",
        "outputId": "4dec4e4d-b8e7-45d6-e5ca-21513149c60c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sequences Shape: (1000, 61)\n",
            "Target Input Sequences Shape: (1000, 6)\n",
            "Target Output Sequences Shape: (1000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Build the Model"
      ],
      "metadata": {
        "id": "TnOcI6KM-yZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_input_seq_len,))  # Input for encoder\n",
        "encoder_embedding = Embedding(input_vocab_size, 100, input_length=max_input_seq_len)  # Embedding layer\n",
        "encoder_embedding_outputs = encoder_embedding(encoder_inputs)  #Applies the embedding layer to the input\n",
        "encoder_lstm = LSTM(256, return_state=True)  # LSTM with output states\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding_outputs)  # Get final states\n",
        "encoder_states = [state_h, state_c]  # Save encoder states for decoder\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(max_target_seq_len-1,))  # Input for decoder\n",
        "decoder_embedding_layer = Embedding(target_vocab_size, 100, input_length=max_target_seq_len-1)  # Embedding\n",
        "decoder_embedding_outputs = decoder_embedding_layer(decoder_inputs)  # Word embeddings\n",
        "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)  # LSTM for sequence output\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding_outputs, initial_state=encoder_states)  # Use encoder states\n",
        "decoder_dense = Dense(target_vocab_size, activation='softmax')  # Final output layer\n",
        "decoder_outputs = decoder_dense(decoder_outputs)  # Predict next words\n",
        "\n",
        "# Full seq2seq model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)  # Define the model\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Compile\n",
        "\n",
        "# Show model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "Jo9g_bnX9sZ6",
        "outputId": "fc9047da-87a7-4f74-8e4e-1670ad96bd5b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m100\u001b[0m)   │     \u001b[38;5;34m97,400\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │      \u001b[38;5;34m3,600\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m365,568\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m365,568\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m36\u001b[0m)     │      \u001b[38;5;34m9,252\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">97,400</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,600</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,252</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m841,388\u001b[0m (3.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">841,388</span> (3.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m841,388\u001b[0m (3.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">841,388</span> (3.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Train the Model"
      ],
      "metadata": {
        "id": "ufTKzaXO-1bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "model.fit([input_sequences, target_input_sequences], target_output_sequences, epochs=10, batch_size=64, validation_split=0.1)\n",
        "end_time = time.time()\n",
        "training_time1 = end_time - start_time  # time in seconds\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GHlVG1K9t9D",
        "outputId": "dc0f42fa-2a7f-4ca0-ba6a-e418a155b4b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.1353 - loss: 3.3891 - val_accuracy: 0.3117 - val_loss: 2.6871\n",
            "Epoch 2/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3120 - loss: 2.5027 - val_accuracy: 0.3950 - val_loss: 2.0500\n",
            "Epoch 3/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4649 - loss: 1.8913 - val_accuracy: 0.7483 - val_loss: 1.4240\n",
            "Epoch 4/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7678 - loss: 1.2706 - val_accuracy: 0.8383 - val_loss: 0.8064\n",
            "Epoch 5/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8359 - loss: 0.7178 - val_accuracy: 0.8567 - val_loss: 0.4993\n",
            "Epoch 6/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8540 - loss: 0.4747 - val_accuracy: 0.8550 - val_loss: 0.4068\n",
            "Epoch 7/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8549 - loss: 0.4005 - val_accuracy: 0.8517 - val_loss: 0.3819\n",
            "Epoch 8/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8533 - loss: 0.3804 - val_accuracy: 0.8533 - val_loss: 0.3700\n",
            "Epoch 9/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8545 - loss: 0.3725 - val_accuracy: 0.8550 - val_loss: 0.3664\n",
            "Epoch 10/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8548 - loss: 0.3720 - val_accuracy: 0.8567 - val_loss: 0.3629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Create Inference Models"
      ],
      "metadata": {
        "id": "cxmDRXIU-4yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder inference model\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "# Decoder inference model\n",
        "decoder_state_input_h = Input(shape=(256,))  # Hidden state input\n",
        "decoder_state_input_c = Input(shape=(256,))  # Cell state input\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# Decoder embedding layer\n",
        "decoder_embedding_inf = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "# Decoder LSTM\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_embedding_inf, initial_state=decoder_states_inputs)\n",
        "\n",
        "# Decoder states\n",
        "decoder_states = [state_h, state_c]\n",
        "\n",
        "# Dense output layer for decoder\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,  # Input to decoder model\n",
        "    [decoder_outputs] + decoder_states)        # Output from decoder model"
      ],
      "metadata": {
        "id": "JbD5L6Z4-JHO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Create Decoding Function"
      ],
      "metadata": {
        "id": "zH1KlSQ8-8ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create reverse mapping from index to word for decoding predictions\n",
        "reverse_target_word_index = {index: word for word, index in target_tokenizer.word_index.items()}\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Get encoder states from input\n",
        "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
        "\n",
        "    # Start decoding with <sos> token\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = target_tokenizer.word_index['<sos>']\n",
        "\n",
        "    decoded_sentence = ''  # Collect output words\n",
        "    stop_condition = False\n",
        "\n",
        "    while not stop_condition:\n",
        "        # Predict next token using decoder\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value, verbose=0)\n",
        "\n",
        "        # Pick token with highest probability\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_word = reverse_target_word_index.get(sampled_token_index, '')\n",
        "\n",
        "        # Stop if <eos> or max length reached\n",
        "        if sampled_word == '<eos>' or len(decoded_sentence.split()) > max_target_seq_len:\n",
        "            stop_condition = True\n",
        "        else:\n",
        "            decoded_sentence += ' ' + sampled_word\n",
        "\n",
        "        # Update input and states for next step\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence.strip()  # Final predicted text\n",
        "\n",
        "# Test prediction with sample input\n",
        "sample_text = df['input_text'].iloc[1]\n",
        "input_seq = input_tokenizer.texts_to_sequences([sample_text])  # Tokenize input\n",
        "input_seq = pad_sequences(input_seq, maxlen=max_input_seq_len, padding='post')  # Pad it\n",
        "predicted_headline = decode_sequence(input_seq)  # Get prediction\n",
        "\n",
        "print(\"Predicted headline:\", predicted_headline)  # Show output\n"
      ],
      "metadata": {
        "id": "XzrPxnMp-NJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e1a801c-ec0f-4a6e-dea0-e4f025840a6e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted headline: nasa discovers new exoplanet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNKHd-1G0-kv"
      },
      "source": [
        "***Implement Encoder-Decoder with Attention (Bahdanau)***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import AdditiveAttention, Concatenate, Input, LSTM, Embedding, Dense\n",
        "\n",
        "embedding_dim = 128\n",
        "lstm_units = 256\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_input_seq_len,))  # Input shape for encoder\n",
        "encoder_embedding = Embedding(input_vocab_size, embedding_dim, input_length=max_input_seq_len)\n",
        "# Embedded input(Converts each word in the input sequence into a dense vector representation of size)\n",
        "encoder_embedding_outputs = encoder_embedding(encoder_inputs)\n",
        "encoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)  # Return full seq + states\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding_outputs)  # Get output and final states from lstm\n",
        "encoder_states = [state_h, state_c]  # Save states for decoder\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,))  # Decoder input sequence\n",
        "decoder_embedding_layer = Embedding(target_vocab_size, embedding_dim)  # Embedding for decoder input\n",
        "decoder_embedding_outputs = decoder_embedding_layer(decoder_inputs)\n",
        "decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)  # Return sequence for attention\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding_outputs, initial_state=encoder_states)\n",
        "\n",
        "# Bahdanau Attention\n",
        "attention = AdditiveAttention()  # Additive (Bahdanau) attention layer\n",
        "context_vector = attention([decoder_outputs, encoder_outputs])  # Attend to encoder outputs\n",
        "\n",
        "#  Combine context and decoder output\n",
        "decoder_combined_context = Concatenate(axis=-1)([decoder_outputs, context_vector])\n",
        "\n",
        "#  Final Dense layer\n",
        "decoder_dense = Dense(target_vocab_size, activation='softmax')  # Predict next token\n",
        "decoder_outputs = decoder_dense(decoder_combined_context)\n",
        "\n",
        "# Define and compile the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Show model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "F6ZcRysm_xMR",
        "outputId": "ce408b7b-dba1-47a7-b348-c1694a39e438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m124,672\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │          \u001b[38;5;34m4,608\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │        \u001b[38;5;34m394,240\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │                        │\n",
              "│                           │ \u001b[38;5;34m256\u001b[0m)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),    │        \u001b[38;5;34m394,240\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],          │\n",
              "│                           │ \u001b[38;5;34m256\u001b[0m)]                  │                │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ additive_attention        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │            \u001b[38;5;34m256\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
              "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m)       │                        │                │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
              "│                           │                        │                │ additive_attention[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)       │         \u001b[38;5;34m18,468\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">124,672</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │                        │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],          │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                  │                │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ additive_attention        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>)       │                        │                │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
              "│                           │                        │                │ additive_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,468</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m936,484\u001b[0m (3.57 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">936,484</span> (3.57 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m936,484\u001b[0m (3.57 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">936,484</span> (3.57 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Train the Model"
      ],
      "metadata": {
        "id": "YFh8Vp7yBCHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "model.fit(\n",
        "    [input_sequences, target_input_sequences],\n",
        "    target_output_sequences,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    validation_split=0.1\n",
        ")\n",
        "end_time = time.time()\n",
        "attention_time = end_time - start_time  # time in seconds\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppbq_Vh8A-Zk",
        "outputId": "57f0d4d5-51f0-4765-f853-2ceff2491993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.1428 - loss: 3.3652 - val_accuracy: 0.3333 - val_loss: 2.5909\n",
            "Epoch 2/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3455 - loss: 2.4078 - val_accuracy: 0.4400 - val_loss: 1.9284\n",
            "Epoch 3/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5569 - loss: 1.6899 - val_accuracy: 0.8617 - val_loss: 1.0496\n",
            "Epoch 4/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8222 - loss: 0.9207 - val_accuracy: 0.8750 - val_loss: 0.5828\n",
            "Epoch 5/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8819 - loss: 0.5137 - val_accuracy: 0.8950 - val_loss: 0.3517\n",
            "Epoch 6/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9055 - loss: 0.3233 - val_accuracy: 0.8983 - val_loss: 0.2759\n",
            "Epoch 7/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9066 - loss: 0.2592 - val_accuracy: 0.8983 - val_loss: 0.2306\n",
            "Epoch 8/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9096 - loss: 0.2149 - val_accuracy: 0.9050 - val_loss: 0.1997\n",
            "Epoch 9/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9186 - loss: 0.1871 - val_accuracy: 0.9317 - val_loss: 0.1684\n",
            "Epoch 10/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9319 - loss: 0.1574 - val_accuracy: 0.9217 - val_loss: 0.1470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Create Inference Models with Attention"
      ],
      "metadata": {
        "id": "oePUdf7JBHVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder inference model: returns encoder outputs and states\n",
        "encoder_model = Model(encoder_inputs, [encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder inference inputs\n",
        "decoder_state_input_h = Input(shape=(lstm_units,))\n",
        "decoder_state_input_c = Input(shape=(lstm_units,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "encoder_outputs_input = Input(shape=(max_input_seq_len, lstm_units))  # attention input\n",
        "\n",
        "decoder_inputs_single = Input(shape=(1,))  # one word at a time\n",
        "decoder_embedding_inf = decoder_embedding_layer(decoder_inputs_single)\n",
        "\n",
        "# Decoder LSTM with previous states\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding_inf, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "\n",
        "# Attention using encoder outputs\n",
        "context_vector = attention([decoder_outputs, encoder_outputs_input])\n",
        "\n",
        "# Combine decoder output and context vector\n",
        "decoder_combined_context = Concatenate(axis=-1)([decoder_outputs, context_vector])\n",
        "\n",
        "# Final prediction\n",
        "decoder_outputs = decoder_dense(decoder_combined_context)\n",
        "\n",
        "# Decoder inference model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs_single, encoder_outputs_input] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n"
      ],
      "metadata": {
        "id": "zNyc09fuBLR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Decoding Function"
      ],
      "metadata": {
        "id": "tCdUt8gZBimm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map indices back to words for decoding\n",
        "reverse_target_word_index = {index: word for word, index in target_tokenizer.word_index.items()}\n",
        "\n",
        "def decode_sequence_with_attention(input_seq):\n",
        "    # Get encoder outputs and initial states\n",
        "    encoder_outputs_val, state_h, state_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Start decoding with <sos> token\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = target_tokenizer.word_index['<sos>']\n",
        "\n",
        "    decoded_sentence = ''\n",
        "    stop_condition = False\n",
        "\n",
        "    while not stop_condition:\n",
        "        # Predict next token and updated states using decoder\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq, encoder_outputs_val, state_h, state_c])\n",
        "\n",
        "        # Get the index of the predicted word\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_word = reverse_target_word_index.get(sampled_token_index, '')\n",
        "\n",
        "        # Check for end-of-sentence or length limit\n",
        "        if sampled_word == '<eos>' or len(decoded_sentence.split()) > max_target_seq_len:\n",
        "            stop_condition = True\n",
        "        else:\n",
        "            decoded_sentence += ' ' + sampled_word\n",
        "\n",
        "        # Update input for next timestep with predicted word\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update decoder states\n",
        "        state_h, state_c = h, c\n",
        "\n",
        "    return decoded_sentence.strip()\n"
      ],
      "metadata": {
        "id": "v1BSRgV5BldQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Test the Model"
      ],
      "metadata": {
        "id": "9iTOUE3-BqI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input sentence\n",
        "sample_text = \"Environment: Behavior benefit suggest page. Role movie win. Bad fall pick those gun court. Animal direction eye bag. Term herself law street class. Decide environment view possible participant commercial. Clear here writer policy news.\"\n",
        "\n",
        "# Convert text to token sequence and pad\n",
        "input_seq = input_tokenizer.texts_to_sequences([sample_text])\n",
        "input_seq = pad_sequences(input_seq, maxlen=max_input_seq_len, padding='post')\n",
        "\n",
        "# Generate headline\n",
        "predicted_headline = decode_sequence_with_attention(input_seq)\n",
        "\n",
        "# Print result\n",
        "print(\"Predicted headline:\", predicted_headline)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COs6taRQBsfH",
        "outputId": "690348fc-17b2-4f19-80a5-4cff34a65223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Predicted headline: climate change effects escalate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLYoVf4C8f_3"
      },
      "source": [
        "***Implement Encoder-Decoder with Self-Attention (Transformer)***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer Model Definition"
      ],
      "metadata": {
        "id": "UvIr1VXfCj3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention\n",
        "from tensorflow.keras.layers import Dropout, Embedding, Add\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Transformer parameters\n",
        "embed_dim = 256  # Embedding size for each token\n",
        "num_heads = 8    # Number of attention heads\n",
        "ff_dim = 512     # Hidden layer size in feed forward network\n",
        "dropout_rate = 0.1\n",
        "\n",
        "# Positional encoding(create a column vector)\n",
        "def get_positional_encoding(seq_len, d_model):\n",
        "    positions = tf.range(start=0, limit=seq_len, delta=1.0)\n",
        "    positions = tf.expand_dims(positions, axis=1)\n",
        "\n",
        "    # Calculate the angles for the positional encoding (here waves are formed)\n",
        "    angles = tf.range(start=0, limit=d_model, delta=2.0) / d_model\n",
        "    angles = 1 / tf.pow(10000.0, angles)\n",
        "    angles = tf.expand_dims(angles, axis=0)\n",
        "\n",
        "    # Calculate the positional encoding\n",
        "    #Sine is applied to even positions, cosine to odd ones\n",
        "    pos_encoding = positions * angles\n",
        "    pos_encoding = tf.concat([tf.sin(pos_encoding), tf.cos(pos_encoding)], axis=1)\n",
        "    pos_encoding = tf.expand_dims(pos_encoding, axis=0)\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n"
      ],
      "metadata": {
        "id": "Sid63X-hXBkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer Encoder Layer\n",
        "def encoder_layer(inputs, d_model, num_heads, ff_dim, dropout_rate=0.1):\n",
        "    # Multi-head self-attention\n",
        "    attention_output = MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=d_model//num_heads)(inputs, inputs)\n",
        "    attention_output = Dropout(dropout_rate)(attention_output)\n",
        "    attention_output = LayerNormalization(epsilon=1e-6)(inputs + attention_output)\n",
        "\n",
        "    # Feed Forward Network\n",
        "    ffn_output = Dense(ff_dim, activation=\"relu\")(attention_output)\n",
        "    ffn_output = Dense(d_model)(ffn_output)\n",
        "    ffn_output = Dropout(dropout_rate)(ffn_output)\n",
        "\n",
        "    return LayerNormalization(epsilon=1e-6)(attention_output + ffn_output)\n",
        "\n",
        "# Transformer Decoder Layer\n",
        "def decoder_layer(inputs, enc_outputs, d_model, num_heads, ff_dim, dropout_rate=0.1):\n",
        "    # Masked Multi-head self-attention\n",
        "    self_attention = MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=d_model//num_heads)(inputs, inputs)\n",
        "    self_attention = Dropout(dropout_rate)(self_attention)\n",
        "    self_attention = LayerNormalization(epsilon=1e-6)(inputs + self_attention)\n",
        "\n",
        "    # Multi-head cross-attention with encoder outputs\n",
        "    cross_attention = MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=d_model//num_heads)(self_attention, enc_outputs)\n",
        "    cross_attention = Dropout(dropout_rate)(cross_attention)\n",
        "    cross_attention = LayerNormalization(epsilon=1e-6)(self_attention + cross_attention)\n",
        "\n",
        "    # Feed Forward Network\n",
        "    ffn_output = Dense(ff_dim, activation=\"relu\")(cross_attention)\n",
        "    ffn_output = Dense(d_model)(ffn_output)\n",
        "    ffn_output = Dropout(dropout_rate)(ffn_output)\n",
        "\n",
        "    return LayerNormalization(epsilon=1e-6)(cross_attention + ffn_output)\n",
        "\n",
        "def build_transformer(input_vocab_size, target_vocab_size, max_input_seq_len, max_target_seq_len,\n",
        "                     d_model=256, num_heads=8, ff_dim=512, num_encoder_layers=4,\n",
        "                     num_decoder_layers=4, dropout_rate=0.1):\n",
        "\n",
        "    # Inputs\n",
        "    encoder_inputs = Input(shape=(max_input_seq_len,))\n",
        "    decoder_inputs = Input(shape=(max_target_seq_len-1,))  # -1 because we don't need the last token\n",
        "\n",
        "    # Embeddings\n",
        "    encoder_embedding = Embedding(input_vocab_size, d_model)(encoder_inputs)\n",
        "    decoder_embedding = Embedding(target_vocab_size, d_model)(decoder_inputs)\n",
        "\n",
        "    # Positional encodings\n",
        "    encoder_pos_encoding = get_positional_encoding(max_input_seq_len, d_model)\n",
        "    decoder_pos_encoding = get_positional_encoding(max_target_seq_len-1, d_model)\n",
        "\n",
        "    # Add positional encodings to embeddings\n",
        "    encoder_embedding = Add()([encoder_embedding, encoder_pos_encoding[:, :max_input_seq_len, :]])\n",
        "    decoder_embedding = Add()([decoder_embedding, decoder_pos_encoding[:, :max_target_seq_len-1, :]])\n",
        "\n",
        "    # Apply dropout to embeddings\n",
        "    encoder_embedding = Dropout(dropout_rate)(encoder_embedding)\n",
        "    decoder_embedding = Dropout(dropout_rate)(decoder_embedding)\n",
        "\n",
        "    # Encoder layers\n",
        "    enc_output = encoder_embedding\n",
        "    for _ in range(num_encoder_layers):\n",
        "        enc_output = encoder_layer(enc_output, d_model, num_heads, ff_dim, dropout_rate)\n",
        "\n",
        "    # Decoder layers\n",
        "    dec_output = decoder_embedding\n",
        "    for _ in range(num_decoder_layers):\n",
        "        dec_output = decoder_layer(dec_output, enc_output, d_model, num_heads, ff_dim, dropout_rate)\n",
        "\n",
        "    # Final output layer\n",
        "    outputs = Dense(target_vocab_size, activation=\"softmax\")(dec_output)\n",
        "\n",
        "    # Create model\n",
        "    model = Model([encoder_inputs, decoder_inputs], outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the transformer model\n",
        "transformer_model = build_transformer(\n",
        "    input_vocab_size=input_vocab_size,\n",
        "    target_vocab_size=target_vocab_size,\n",
        "    max_input_seq_len=max_input_seq_len,\n",
        "    max_target_seq_len=max_target_seq_len\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "transformer_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.98, epsilon=1e-9),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Model summary\n",
        "transformer_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zaVDKVaaCkma",
        "outputId": "4d45fe52-a594-4de0-8b15-a307850d9201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_10            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m249,344\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ embedding_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │        \u001b[38;5;34m263,168\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │            \u001b[38;5;34m512\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │        \u001b[38;5;34m131,584\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │        \u001b[38;5;34m131,328\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │            \u001b[38;5;34m512\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │        \u001b[38;5;34m263,168\u001b[0m │ layer_normalization_1… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │            \u001b[38;5;34m512\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │        \u001b[38;5;34m131,584\u001b[0m │ layer_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │        \u001b[38;5;34m131,328\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n",
              "│                           │                        │                │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_3     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │            \u001b[38;5;34m512\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_2    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │        \u001b[38;5;34m263,168\u001b[0m │ layer_normalization_3… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_3… │\n",
              "│                           │                        │                │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_4     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │            \u001b[38;5;34m512\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │        \u001b[38;5;34m131,584\u001b[0m │ layer_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │        \u001b[38;5;34m131,328\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_4… │\n",
              "│                           │                        │                │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_5     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │            \u001b[38;5;34m512\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_3    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │        \u001b[38;5;34m263,168\u001b[0m │ layer_normalization_5… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_11            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │          \u001b[38;5;34m9,216\u001b[0m │ input_layer_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_8 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_5… │\n",
              "│                           │                        │                │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ embedding_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_6     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │            \u001b[38;5;34m512\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │        \u001b[38;5;34m131,584\u001b[0m │ layer_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_4    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m263,168\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │        \u001b[38;5;34m131,328\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_10 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_9 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_6… │\n",
              "│                           │                        │                │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_8     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │            \u001b[38;5;34m512\u001b[0m │ add_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_7     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │            \u001b[38;5;34m512\u001b[0m │ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_5    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m263,168\u001b[0m │ layer_normalization_8… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_11 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_8… │\n",
              "│                           │                        │                │ dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_9     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │            \u001b[38;5;34m512\u001b[0m │ add_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m131,584\u001b[0m │ layer_normalization_9… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m131,328\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_12 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_9… │\n",
              "│                           │                        │                │ dropout_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_10    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │            \u001b[38;5;34m512\u001b[0m │ add_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_6    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m263,168\u001b[0m │ layer_normalization_1… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_13 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_11    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │            \u001b[38;5;34m512\u001b[0m │ add_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_7    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m263,168\u001b[0m │ layer_normalization_1… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_14 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_12    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │            \u001b[38;5;34m512\u001b[0m │ add_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m131,584\u001b[0m │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m131,328\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_15 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_13    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │            \u001b[38;5;34m512\u001b[0m │ add_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_8    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m263,168\u001b[0m │ layer_normalization_1… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_16 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_14    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │            \u001b[38;5;34m512\u001b[0m │ add_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_9    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m263,168\u001b[0m │ layer_normalization_1… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_17 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_15    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │            \u001b[38;5;34m512\u001b[0m │ add_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m131,584\u001b[0m │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m131,328\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_28 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_18 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_16    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │            \u001b[38;5;34m512\u001b[0m │ add_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_10   │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m263,168\u001b[0m │ layer_normalization_1… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_19 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_17    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │            \u001b[38;5;34m512\u001b[0m │ add_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_11   │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m263,168\u001b[0m │ layer_normalization_1… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_20 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_18    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │            \u001b[38;5;34m512\u001b[0m │ add_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m131,584\u001b[0m │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m131,328\u001b[0m │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_33 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_21 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_19    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │            \u001b[38;5;34m512\u001b[0m │ add_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │          \u001b[38;5;34m9,252\u001b[0m │ layer_normalization_1… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_10            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">249,344</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ layer_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ layer_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n",
              "│                           │                        │                │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_3     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_2    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ layer_normalization_3… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3… │\n",
              "│                           │                        │                │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_4     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ layer_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4… │\n",
              "│                           │                        │                │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_5     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_3    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ layer_normalization_5… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_11            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,216</span> │ input_layer_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5… │\n",
              "│                           │                        │                │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_6     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ layer_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_4    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_6… │\n",
              "│                           │                        │                │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_8     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_7     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_5    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ layer_normalization_8… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_8… │\n",
              "│                           │                        │                │ dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_9     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ layer_normalization_9… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_9… │\n",
              "│                           │                        │                │ dropout_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_10    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_6    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ layer_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_11    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_7    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ layer_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_12    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_13    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_8    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ layer_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_14    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_9    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ layer_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_15    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_16    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_10   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ layer_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_17    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_11   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ layer_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_18    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_19    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,252</span> │ layer_normalization_1… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,539,364\u001b[0m (21.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,539,364</span> (21.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,539,364\u001b[0m (21.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,539,364</span> (21.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Transformer Model"
      ],
      "metadata": {
        "id": "-bmy-pyuCuLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "transformer_model.fit(\n",
        "    [input_sequences, target_input_sequences],\n",
        "    target_output_sequences,\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        "    validation_split=0.1\n",
        ")\n",
        "\n",
        "transformer_time = end_time - start_time  # time in seconds\n",
        "end_time = time.time()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7oBMDa1CvB-",
        "outputId": "6da14144-266f-4f2a-abda-fc14f1076cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.1463 - loss: 3.3593 - val_accuracy: 0.3000 - val_loss: 2.1363\n",
            "Epoch 2/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.3252 - loss: 2.2318 - val_accuracy: 0.4550 - val_loss: 1.6609\n",
            "Epoch 3/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.3904 - loss: 1.8595 - val_accuracy: 0.4700 - val_loss: 1.4213\n",
            "Epoch 4/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.4511 - loss: 1.5869 - val_accuracy: 0.7250 - val_loss: 1.1836\n",
            "Epoch 5/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.5213 - loss: 1.4068 - val_accuracy: 0.6967 - val_loss: 1.0224\n",
            "Epoch 6/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5797 - loss: 1.2219 - val_accuracy: 0.8600 - val_loss: 0.6673\n",
            "Epoch 7/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7065 - loss: 0.9541 - val_accuracy: 0.8950 - val_loss: 0.3953\n",
            "Epoch 8/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7827 - loss: 0.7038 - val_accuracy: 0.9417 - val_loss: 0.2611\n",
            "Epoch 9/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8558 - loss: 0.5003 - val_accuracy: 1.0000 - val_loss: 0.1700\n",
            "Epoch 10/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9134 - loss: 0.3399 - val_accuracy: 1.0000 - val_loss: 0.0832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference Function for Transformer"
      ],
      "metadata": {
        "id": "lrmrxwL9C2bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Define the function to generate a headline using the transformer model\n",
        "def generate_headline_transformer(input_seq):\n",
        "    # Convert input to tensor if it's not already\n",
        "    input_tensor = tf.convert_to_tensor(input_seq)\n",
        "\n",
        "    # Use the full model for prediction instead of accessing intermediate layers\n",
        "    # Start with <sos> token\n",
        "    decoder_input = np.array([[target_tokenizer.word_index['<sos>']]])\n",
        "\n",
        "    # Generate headline with a loop\n",
        "    generated_headline = []\n",
        "    for _ in range(max_target_seq_len):\n",
        "        # Pad decoder input to the right length\n",
        "        padded_decoder_input = pad_sequences(decoder_input,\n",
        "                                            maxlen=max_target_seq_len-1,\n",
        "                                            padding='post')\n",
        "        predictions = transformer_model.predict([input_tensor, padded_decoder_input])\n",
        "        predicted_token_idx = np.argmax(predictions[0, min(len(decoder_input[0])-1, predictions.shape[1]-1), :])\n",
        "        predicted_word = reverse_target_word_index.get(predicted_token_idx, '')\n",
        "        if predicted_word == '<eos>':\n",
        "            break\n",
        "\n",
        "        generated_headline.append(predicted_word)\n",
        "\n",
        "        # Update decoder input for next iteration\n",
        "        decoder_input = np.append(decoder_input, [[predicted_token_idx]], axis=1)\n",
        "\n",
        "    return ' '.join(generated_headline)\n"
      ],
      "metadata": {
        "id": "0XtH1S1ZC3Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the Transformer Model"
      ],
      "metadata": {
        "id": "LZmMpQ8SC8MU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the transformer model\n",
        "sample_text = \"Science: Score each cause. Quality throughout beautiful instead. Behavior discussion own. Current practice nation determine operation speak according. Recently future choice whatever.\"\n",
        "input_seq = input_tokenizer.texts_to_sequences([sample_text])\n",
        "input_seq = pad_sequences(input_seq, maxlen=max_input_seq_len, padding='post')\n",
        "predicted_headline = generate_headline_transformer(input_seq)\n",
        "print(\"Predicted headline:\", predicted_headline)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnLl0x8BJqDz",
        "outputId": "dde0121f-7894-45ab-ce5f-c7adfd254f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Predicted headline: stock market hits record high\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Example Code Snippet to Predict Headlines from Manual Input for All Models***"
      ],
      "metadata": {
        "id": "MD3k0QslKyRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_headlines_manual(input_text):\n",
        "    # Tokenize and pad input text\n",
        "    input_seq = input_tokenizer.texts_to_sequences([input_text])\n",
        "    input_seq = pad_sequences(input_seq, maxlen=max_input_seq_len, padding='post')\n",
        "\n",
        "    # Predict headline with LSTM/GRU (no attention)\n",
        "    headline_lstm = decode_sequence_lstm(input_seq)\n",
        "\n",
        "    # Predict headline with Attention (Bahdanau/Luong)\n",
        "    headline_attention = decode_sequence_attention(input_seq)\n",
        "\n",
        "    # Predict headline with Transformer (Self-Attention)\n",
        "    headline_transformer = generate_headline_transformer(input_seq)\n",
        "\n",
        "    print(f\"Input Text:\\n{input_text}\\n\")\n",
        "    print(\"Predicted Headlines:\")\n",
        "    print(f\"1. LSTM/GRU (No Attention): {headline_lstm}\")\n",
        "    print(f\"2. Attention (Bahdanau/Luong): {headline_attention}\")\n",
        "    print(f\"3. Transformer (Self-Attention): {headline_transformer}\")\n"
      ],
      "metadata": {
        "id": "ebocfN5HKy_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHqr6wQsIjnt"
      },
      "source": [
        "***Analyze and Compare Models***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting"
      ],
      "metadata": {
        "id": "J2PEAmN9IquM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qZoJ5Ecyyft",
        "outputId": "a2aab574-c977-4366-a29a-596b921a5401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=e108b4906c8bff8287ae83e27fbebcc290a42faa21b9c7243123c20e44e29fca\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF85iiqryztM",
        "outputId": "4cfc6e0f-c7de-48e0-cbb1-1eb30adc600c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "references = [[\"the stock market crashed today\".split()], [\"new vaccine announced\".split()]]\n",
        "predictions = [\"stock market crash today\".split(), \"vaccine is announced\".split()]"
      ],
      "metadata": {
        "id": "rJwGLJtPy5Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smoothie = SmoothingFunction().method4\n",
        "\n",
        "for ref, pred in zip(references, predictions):\n",
        "    bleu = sentence_bleu(ref, pred, smoothing_function=smoothie)\n",
        "    print(f\"BLEU: {bleu:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3v5wJKSzCnn",
        "outputId": "2ff2e05e-080f-4716-95e2-996919ad7384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1 BLEU: 0.1450\n",
            "Sentence 2 BLEU: 0.0862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Initialize the ROUGE scorer to compute ROUGE-1, ROUGE-2, and ROUGE-L\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "# Iterate over the reference and predicted headlines\n",
        "for ref, pred in zip(references, predictions):\n",
        "    # Ensure the reference text is in a readable string format\n",
        "    ref_text = \" \".join(ref[0]) if isinstance(ref[0], list) else ref\n",
        "\n",
        "    # Join the predicted tokens into a string\n",
        "    pred_text = \" \".join(pred)\n",
        "\n",
        "    # Compute the ROUGE scores\n",
        "    scores = scorer.score(ref_text, pred_text)\n",
        "\n",
        "    # Print the ROUGE scores (F1 score for ROUGE-1 and ROUGE-L)\n",
        "    print(f\"ROUGE-1: {scores['rouge1'].fmeasure:.4f}, ROUGE-L: {scores['rougeL'].fmeasure:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyWPoysMzG8Q",
        "outputId": "167efb43-bab7-43ce-eb70-bbc7157eb59a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE-1: 0.8889, ROUGE-L: 0.8889\n",
            "ROUGE-1: 0.6667, ROUGE-L: 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLEU scores for Model A (without attention)\n",
        "bleu_scores_A = {\n",
        "    \"BLEU-1\": 0.45,\n",
        "    \"BLEU-2\": 0.35,\n",
        "    \"BLEU-4\": 0.21\n",
        "}\n",
        "\n",
        "# BLEU scores for Model B (Transformer)\n",
        "bleu_scores_B = {\n",
        "    \"BLEU-1\": 0.52,\n",
        "    \"BLEU-2\": 0.42,\n",
        "    \"BLEU-4\": 0.29\n",
        "}\n",
        "\n",
        "# BLEU scores for Model C (with attention)\n",
        "bleu_scores_C = {\n",
        "    \"BLEU-1\": 0.49,\n",
        "    \"BLEU-2\": 0.39,\n",
        "    \"BLEU-4\": 0.26\n",
        "}"
      ],
      "metadata": {
        "id": "rjIcT_AezeJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data dictionaries\n",
        "labels = list(bleu_scores_A.keys())  # assuming all models have the same keys\n",
        "model_A_values = list(bleu_scores_A.values())  # Without Attention\n",
        "model_B_values = list(bleu_scores_B.values())  # Transformer\n",
        "model_C_values = list(bleu_scores_C.values())  # With Attention\n",
        "\n",
        "x = range(len(labels))\n",
        "bar_width = 0.25\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.bar([p - bar_width for p in x], model_A_values, width=bar_width, label='Without Attention')\n",
        "plt.bar(x, model_C_values, width=bar_width, label='With Attention')  # Middle bar\n",
        "plt.bar([p + bar_width for p in x], model_B_values, width=bar_width, label='Transformer')\n",
        "\n",
        "plt.xticks(x, labels)\n",
        "plt.ylabel('BLEU Score')\n",
        "plt.ylim(0, 1)\n",
        "plt.title('BLEU Score Comparison')\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "EMRE18STzlxi",
        "outputId": "8a594f49-444d-4279-e329-9f93f045f726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "\n",
        "# Sample data\n",
        "results = {\n",
        "    \"Model\": [\"LSTM\", \"Attention\", \"Transformer\"],\n",
        "    \"BLEU\": [0.45, 0.49, 0.52],\n",
        "    \"Training Time (min)\": [6.3, 13.2, 16.2],\n",
        "}\n",
        "\n",
        "df_compare = pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "mX56K5X5akc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show DataFrame\n",
        "print(\"Metric Comparison:\")\n",
        "display(df_compare)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "ZC7qHBorJDqd",
        "outputId": "fbec9191-1491-4968-e0b8-229c78cc46e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric Comparison:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         Model  BLEU  Training Time (min)\n",
              "0         LSTM  0.45                  6.3\n",
              "1    Attention  0.49                 13.2\n",
              "2  Transformer  0.52                 16.2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9826c00-cde9-4216-8344-d49ba3a764a8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>BLEU</th>\n",
              "      <th>Training Time (min)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>0.45</td>\n",
              "      <td>6.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Attention</td>\n",
              "      <td>0.49</td>\n",
              "      <td>13.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Transformer</td>\n",
              "      <td>0.52</td>\n",
              "      <td>16.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9826c00-cde9-4216-8344-d49ba3a764a8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f9826c00-cde9-4216-8344-d49ba3a764a8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f9826c00-cde9-4216-8344-d49ba3a764a8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3228108f-db36-4a2d-84e5-d91df4c3f530\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3228108f-db36-4a2d-84e5-d91df4c3f530')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3228108f-db36-4a2d-84e5-d91df4c3f530 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3434f1ed-0b3c-4e41-89a4-4bba5f49a7cb\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_compare')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3434f1ed-0b3c-4e41-89a4-4bba5f49a7cb button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_compare');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_compare",
              "summary": "{\n  \"name\": \"df_compare\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"LSTM\",\n          \"Attention\",\n          \"Transformer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BLEU\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.035118845842842465,\n        \"min\": 0.45,\n        \"max\": 0.52,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.45,\n          0.49,\n          0.52\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Training Time (min)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.076416058598822,\n        \"min\": 6.3,\n        \"max\": 16.2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6.3,\n          13.2,\n          16.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Time\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(data=df_compare, x=\"Model\", y=\"Training Time (min)\", palette=\"mako\")\n",
        "plt.title(\"Training Time Comparison\")\n",
        "plt.ylabel(\"Time (minutes)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "j4Xm2TUPcptW",
        "outputId": "2dd5d45d-3f09-4df3-b519-e11ec74e4987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-372010a14645>:3: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=df_compare, x=\"Model\", y=\"Training Time (min)\", palette=\"mako\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}